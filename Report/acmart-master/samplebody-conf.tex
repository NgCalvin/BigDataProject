\section{Introduction}
Currently, we are all living in a social system under capitalism. Every enterprise is competing with each other with their own products, services and even user experience. With the rapid growth of the internet in recent year, user experience can be further improved via processing huge data on costumer's review and rating. The Large internet-based retailer, like Amazon, have an enormous number of products but obviously, not all of them are popular. Therefore, processing costumer's review and rating of a product is vital for improving user experience thus increasing profit.

In order to determine the popularity of a product, an explicit way is to process costumer's review and rating. Nonetheless, the number of responses on a product would not always be sufficiently large enough for reference. In the Amazon Fine Food Reviews, there are user's scores and reviews on different products and our goal is to investigate the popularity of products by these two factors. This will benefit online retailer to promote further actions to enhance user experience and yield more revenue. Moreover, the system would be able to do predication of rating of the product based on the comment.


\section{Problem Setting}
k-singles on the comments in different rating. k can be changed, we will see the performance on different number of k. k is probably from 1 to 3\\
k-combination problem\\
So there will be 5 category and classify the comment to one of it.\\
Using Hadoop.\\
We will be writing a program that will filter out the stop words.\\
Ignoring the empty comment or defalt value.\\

\begin{enumerate}
\item Work 0: Pre-process : remove stop words (python)
\item work 1: k-singles (support = ?) mapReduce (Hadoop) cut top 100
\item work 2: prediction : weight equation (
\end{enumerate}

Firstly, Put every comments into that rating category and will only left with top 100 FIS. 
The system intake the data set we will be using mapReduce of k-singles on comment and it's count.
Mapper will take in the data result will be <(shingle),<count,rating>,...>
Reducer will be <(shingle),<count,rating>,...>
When a new comment comes in we will compare its k-shingles to the result from Pre-processing result.

\subsection{Basic Statistic of the dataset}

\section{System Structure}
In this project, we will be using python to code the system that perform processing on the data set. There are three stages in the whole system, we will be explaining the idea and coding in the following subsections. Based on the result generated by each stage we can do prediction of rating based on the give comment.
\subsection{Stage 1}
In this subsection, we will be explaining the idea behind stage one, pre-processing. As only small portion of the given data are useful in this project, we need to do pre-processing before doing other applications.

During the pre-process, we will extract rating column, summary column and comment column of each review record. Moreover, we will remove all punctations and selected stopwords from comment part and left with only meaningful words. We need to preserve some stopwords because it effect the real meaning of the comment. For example, "Good" and "Not Good". If we remove stopword "Not", the meaning of the comment is completely reversed.

\begin{table*}
  \caption{Some Typical Commands}
  \label{tab:commands}
  \begin{tabular}{l}
    \toprule
    Id , ProductId, UserId, ProfileName, HelpfullnessNumerator, HelpfullnessDenominator, Score, Time, Summary, Text\\
    \midrule
    1,B001E4KFG0,A3SGXH7AUHU8GW,delmartian,1,1,5,1303862400,Good Quality Dog Food,I have bought... \\
    2,B00813GRG4,A1D87F6ZCVE5NK,dll pa,0,0,1,1346976000,Not as Advertised,"Product arrived labeled...\\
    3,B000LQOCH0,ABXLMWJIXXAIN,"Natalia Corres ""Natalia Corres""",1,1,4,1219017600,"""Delight"" says it all","This is a confection...\\
    4,B000UA0QIQ,A395BORC6FGVXV,Karl,3,3,2,1307923200,Cough Medicine,If you are looking... \\
    \bottomrule
  \end{tabular}
\end{table*}

\begin{table*}
  \caption{Part of Result Dataset}
  \label{tab:commands}
  \begin{tabular}{l}
    \toprule
    Score, Text\\
    \midrule
	5,bought vitality canned dog food products good quality product looks like stew processed meat smells better labrador finicky ... \\ 
	1,product arrived labeled jumbo salted peanutsthe peanuts actually small sized unsalted not sure error vendor intended represent ... \\ 
	4,confection centuriesit light pillowy citrus gelatin nutsin case filberts cut tiny squares liberally coated powdered sugarand tiny ...\\ 
	2,looking secret ingredient robitussin believe iti got addition root beer extract ordered good cherry sodathe flavor medicinal ... \\ 
	\bottomrule
  \end{tabular}
\end{table*}


The original data file is in format of \(.cvs\), each column is separated by a comma and each row is separated by a linebreak. Each row have the format : \{Id , ProductId, UserId, ProfileName, HelpfullnessNumerator, HelpfullnessDenominator, Score, Time, Summary, Text\}. As mentioned before, the only important parts are Score, Summary and Text. Thus, the resulting data have format : \{Score, Summary, Text\}.

Let us observe part of the original data and the result from pre-processing before we explain how we do pre-processing.




\subsection{Stage 2}
Mapper : Data file from pre-processing and with format \{score, text\} with argument top\_max and min\_support, Output \{\{score, shingle length, shingle\},\{1\}\} \\
Reducer : sum all the 1 .\\
Output :  \{ Score, Shingle Length, Frequency, Shingle \}  in csv format \\
Filtering : Cut off top max with argument top\_max.
Each k-shingle(1-5) have a set of output. 
Ignoring shingles with count = 1, because there's too many of it.\\
\subsection{Stage 3}
Prediction : If 
Approach one : Take Mean of all 5 scores of a comment.
Approach two : Take the best score from the 5 scores obtained.
There's a true score.
Test set will compare the true score , avg score , each 1-5 shingles marks. See which one best represent the data.
If there's any shingle don't have any value, avg score of training set.
70\% will be training set 30\% will be testing set. Using pandas to cut it.

\section{Testing}
The system will be taking 70\% of the data set to be based set and the rest as testing and improving the prediction.

Testing result is as following:

\section{Conclusion}
\section{Future Work}
